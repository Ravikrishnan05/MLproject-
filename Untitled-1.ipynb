{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hi i Am Ravikrishnan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.decoder.version', 'model.encoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                      name  \\\n",
      "0   1             Leanne Graham   \n",
      "1   2              Ervin Howell   \n",
      "2   3          Clementine Bauch   \n",
      "3   4          Patricia Lebsack   \n",
      "4   5          Chelsey Dietrich   \n",
      "5   6      Mrs. Dennis Schulist   \n",
      "6   7           Kurtis Weissnat   \n",
      "7   8  Nicholas Runolfsdottir V   \n",
      "8   9           Glenna Reichert   \n",
      "9  10        Clementina DuBuque   \n",
      "\n",
      "                                         news titles  Sports  Medical  Tech  \\\n",
      "0  [sunt aut facere repellat provident occaecati ...       2        5     1   \n",
      "1  [et ea vero quia laudantium autem, in quibusda...       4        4     1   \n",
      "2  [asperiores ea ipsam voluptatibus modi minima ...       3        5     5   \n",
      "3  [ullam ut quidem id aut vel consequuntur, dolo...       1        4     3   \n",
      "4  [non est facere, commodi ullam sint et exceptu...       4        4     1   \n",
      "5  [soluta aliquam aperiam consequatur illo quis ...       2        4     5   \n",
      "6  [voluptatem doloribus consectetur est ut ducim...       1        5     5   \n",
      "7  [et iusto veniam et illum aut fuga, sint hic d...       3        1     2   \n",
      "8  [tempora rem veritatis voluptas quo dolores ve...       1        1     3   \n",
      "9  [aut amet sed, ratione ex tenetur perferendis,...       2        1     4   \n",
      "\n",
      "   Watch Time  \n",
      "0        6.60  \n",
      "1        9.75  \n",
      "2       18.96  \n",
      "3       13.86  \n",
      "4       20.19  \n",
      "5       17.12  \n",
      "6       21.84  \n",
      "7        7.18  \n",
      "8       19.24  \n",
      "9        8.20  \n",
      "                                           News Title  Sports  Medical  Tech\n",
      "0   sunt aut facere repellat provident occaecati e...       0        0     1\n",
      "1                                        qui est esse       0        0     1\n",
      "2   ea molestias quasi exercitationem repellat qui...       1        0     0\n",
      "3                                eum et est occaecati       0        0     1\n",
      "4                                  nesciunt quas odio       0        0     1\n",
      "..                                                ...     ...      ...   ...\n",
      "95  quaerat velit veniam amet cupiditate aut numqu...       0        0     1\n",
      "96         quas fugiat ut perspiciatis vero provident       0        0     1\n",
      "97                        laboriosam dolor voluptates       0        1     0\n",
      "98  temporibus sit alias delectus eligendi possimu...       0        0     1\n",
      "99              at nam consequatur ea labore ea harum       0        1     0\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "   Sports  Medical  Tech\n",
      "0       2        5     1\n",
      "1       4        4     1\n",
      "2       3        5     5\n",
      "3       1        4     3\n",
      "4       4        4     1\n",
      "5       2        4     5\n",
      "6       1        5     5\n",
      "7       3        1     2\n",
      "8       1        1     3\n",
      "9       2        1     4\n",
      "    Sports  Medical  Tech\n",
      "0        0        0     1\n",
      "1        0        0     1\n",
      "2        1        0     0\n",
      "3        0        0     1\n",
      "4        0        0     1\n",
      "..     ...      ...   ...\n",
      "95       0        0     1\n",
      "96       0        0     1\n",
      "97       0        1     0\n",
      "98       0        0     1\n",
      "99       0        1     0\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "[[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452\n",
      "  0.05808361 0.86617615 0.60111501 0.70807258 0.02058449 0.96990985\n",
      "  0.83244264 0.21233911 0.18182497 0.18340451 0.30424224 0.52475643\n",
      "  0.43194502 0.29122914 0.61185289 0.13949386 0.29214465 0.36636184\n",
      "  0.45606998 0.78517596 0.19967378 0.51423444 0.59241457 0.04645041\n",
      "  0.60754485 0.17052412 0.06505159 0.94888554 0.96563203 0.80839735\n",
      "  0.30461377 0.09767211 0.68423303 0.44015249 0.12203823 0.49517691\n",
      "  0.03438852 0.9093204  0.25877998 0.66252228 0.31171108 0.52006802\n",
      "  0.54671028 0.18485446 0.96958463 0.77513282 0.93949894 0.89482735\n",
      "  0.59789998 0.92187424 0.0884925  0.19598286 0.04522729 0.32533033\n",
      "  0.38867729 0.27134903 0.82873751 0.35675333 0.28093451 0.54269608\n",
      "  0.14092422 0.80219698 0.07455064 0.98688694 0.77224477 0.19871568\n",
      "  0.00552212 0.81546143 0.70685734 0.72900717 0.77127035 0.07404465\n",
      "  0.35846573 0.11586906 0.86310343 0.62329813 0.33089802 0.06355835\n",
      "  0.31098232 0.32518332 0.72960618 0.63755747 0.88721274 0.47221493\n",
      "  0.11959425 0.71324479 0.76078505 0.5612772  0.77096718 0.4937956\n",
      "  0.52273283 0.42754102 0.02541913 0.10789143]\n",
      " [0.03142919 0.63641041 0.31435598 0.50857069 0.90756647 0.24929223\n",
      "  0.41038292 0.75555114 0.22879817 0.07697991 0.28975145 0.16122129\n",
      "  0.92969765 0.80812038 0.63340376 0.87146059 0.80367208 0.18657006\n",
      "  0.892559   0.53934224 0.80744016 0.8960913  0.31800347 0.11005192\n",
      "  0.22793516 0.42710779 0.81801477 0.86073058 0.00695213 0.5107473\n",
      "  0.417411   0.22210781 0.11986537 0.33761517 0.9429097  0.32320293\n",
      "  0.51879062 0.70301896 0.3636296  0.97178208 0.96244729 0.2517823\n",
      "  0.49724851 0.30087831 0.28484049 0.03688695 0.60956433 0.50267902\n",
      "  0.05147875 0.27864646 0.90826589 0.23956189 0.14489487 0.48945276\n",
      "  0.98565045 0.24205527 0.67213555 0.76161962 0.23763754 0.72821635\n",
      "  0.36778313 0.63230583 0.63352971 0.53577468 0.09028977 0.8353025\n",
      "  0.32078006 0.18651851 0.04077514 0.59089294 0.67756436 0.01658783\n",
      "  0.51209306 0.22649578 0.64517279 0.17436643 0.69093774 0.38673535\n",
      "  0.93672999 0.13752094 0.34106635 0.11347352 0.92469362 0.87733935\n",
      "  0.25794163 0.65998405 0.8172222  0.55520081 0.52965058 0.24185229\n",
      "  0.09310277 0.89721576 0.90041806 0.63310146 0.33902979 0.34920957\n",
      "  0.72595568 0.89711026 0.88708642 0.77987555]\n",
      " [0.64203165 0.08413996 0.16162871 0.89855419 0.60642906 0.00919705\n",
      "  0.10147154 0.66350177 0.00506158 0.16080805 0.54873379 0.6918952\n",
      "  0.65196126 0.22426931 0.71217922 0.23724909 0.3253997  0.74649141\n",
      "  0.6496329  0.84922341 0.65761289 0.5683086  0.09367477 0.3677158\n",
      "  0.26520237 0.24398964 0.97301055 0.39309772 0.89204656 0.63113863\n",
      "  0.7948113  0.50263709 0.57690388 0.49251769 0.19524299 0.72245212\n",
      "  0.28077236 0.02431597 0.6454723  0.17711068 0.94045858 0.95392858\n",
      "  0.91486439 0.3701587  0.01545662 0.92831856 0.42818415 0.96665482\n",
      "  0.96361998 0.85300946 0.29444889 0.38509773 0.85113667 0.31692201\n",
      "  0.16949275 0.55680126 0.93615477 0.6960298  0.57006117 0.09717649\n",
      "  0.61500723 0.99005385 0.14008402 0.51832965 0.87737307 0.74076862\n",
      "  0.69701574 0.70248408 0.35949115 0.29359184 0.80936116 0.81011339\n",
      "  0.86707232 0.91324055 0.5113424  0.50151629 0.79829518 0.64996393\n",
      "  0.70196688 0.79579267 0.89000534 0.33799516 0.37558295 0.09398194\n",
      "  0.57828014 0.03594227 0.46559802 0.54264463 0.28654125 0.59083326\n",
      "  0.03050025 0.03734819 0.82260056 0.36019064 0.12706051 0.52224326\n",
      "  0.76999355 0.21582103 0.62289048 0.08534746]\n",
      " [0.05168172 0.53135463 0.54063512 0.6374299  0.72609133 0.97585208\n",
      "  0.51630035 0.32295647 0.79518619 0.27083225 0.43897142 0.07845638\n",
      "  0.02535074 0.96264841 0.83598012 0.69597421 0.40895294 0.17329432\n",
      "  0.15643704 0.2502429  0.54922666 0.71459592 0.66019738 0.2799339\n",
      "  0.95486528 0.73789692 0.55435405 0.61172075 0.41960006 0.24773099\n",
      "  0.35597268 0.75784611 0.01439349 0.11607264 0.04600264 0.0407288\n",
      "  0.85546058 0.70365786 0.47417383 0.09783416 0.49161588 0.47347177\n",
      "  0.17320187 0.43385165 0.39850473 0.6158501  0.63509365 0.04530401\n",
      "  0.37461261 0.62585992 0.50313626 0.85648984 0.65869363 0.16293443\n",
      "  0.07056875 0.64241928 0.02651131 0.58577558 0.94023024 0.57547418\n",
      "  0.38816993 0.64328822 0.45825289 0.54561679 0.94146481 0.38610264\n",
      "  0.96119056 0.90535064 0.19579113 0.0693613  0.100778   0.01822183\n",
      "  0.09444296 0.68300677 0.07118865 0.31897563 0.84487531 0.02327194\n",
      "  0.81446848 0.28185477 0.11816483 0.69673717 0.62894285 0.87747201\n",
      "  0.73507104 0.80348093 0.28203457 0.17743954 0.75061475 0.80683474\n",
      "  0.99050514 0.41261768 0.37201809 0.77641296 0.34080354 0.93075733\n",
      "  0.85841275 0.42899403 0.75087107 0.75454287]\n",
      " [0.10312387 0.90255291 0.50525237 0.82645747 0.3200496  0.89552323\n",
      "  0.38920168 0.01083765 0.90538198 0.09128668 0.31931364 0.95006197\n",
      "  0.95060715 0.57343789 0.63183721 0.44844552 0.29321077 0.32866455\n",
      "  0.67251846 0.75237453 0.79157904 0.78961814 0.0912061  0.4944203\n",
      "  0.05755876 0.54952888 0.4415305  0.88770418 0.35091501 0.11706702\n",
      "  0.14299168 0.76151063 0.61821806 0.10112268 0.08410681 0.70096913\n",
      "  0.07276301 0.82186006 0.70624223 0.08134878 0.08483771 0.98663958\n",
      "  0.3742708  0.37064215 0.81279957 0.94724858 0.98600106 0.75337819\n",
      "  0.37625959 0.08350072 0.77714692 0.55840425 0.42422201 0.90635439\n",
      "  0.11119748 0.4926251  0.01135364 0.46866064 0.05630328 0.11881792\n",
      "  0.11752625 0.6492103  0.74604488 0.58336877 0.96217255 0.37487058\n",
      "  0.28571209 0.86859913 0.22359584 0.96322254 0.01215447 0.96987883\n",
      "  0.04315991 0.89114311 0.52770111 0.9929648  0.07379656 0.55385428\n",
      "  0.96930254 0.52309784 0.62939864 0.69574869 0.45454106 0.62755808\n",
      "  0.58431431 0.90115801 0.04544638 0.28096319 0.95041148 0.89026378\n",
      "  0.45565675 0.6201326  0.27738118 0.18812116 0.4636984  0.35335223\n",
      "  0.58365611 0.07773464 0.97439481 0.98621074]\n",
      " [0.69816171 0.53609637 0.30952762 0.81379502 0.68473117 0.16261694\n",
      "  0.91092718 0.82253724 0.94979991 0.72571951 0.6134152  0.41824304\n",
      "  0.93272848 0.86606389 0.04521867 0.02636697 0.37646337 0.81055333\n",
      "  0.98727613 0.15041689 0.59413072 0.38089086 0.9699144  0.84211892\n",
      "  0.8383287  0.46869316 0.4148195  0.27340707 0.0563755  0.86472238\n",
      "  0.81290101 0.99971767 0.99663684 0.55543171 0.76898742 0.94476573\n",
      "  0.84964739 0.2473481  0.45054414 0.12915942 0.95405103 0.60617463\n",
      "  0.22864281 0.67170068 0.61812824 0.35816272 0.11355759 0.6715732\n",
      "  0.5203077  0.77231839 0.5201635  0.8521815  0.55190684 0.56093797\n",
      "  0.8766536  0.40348287 0.13401523 0.02878268 0.75513726 0.62030955\n",
      "  0.70407977 0.21296416 0.13637148 0.01454467 0.35058756 0.58991769\n",
      "  0.39224405 0.43747492 0.90415869 0.34825547 0.51398949 0.78365301\n",
      "  0.39654278 0.6220867  0.86236371 0.94952062 0.14707348 0.92658763\n",
      "  0.49211629 0.25824439 0.45913576 0.98003258 0.49261809 0.32875161\n",
      "  0.63340085 0.24014562 0.07586333 0.12887972 0.12804584 0.15190269\n",
      "  0.13882717 0.64087474 0.18188008 0.34566728 0.89678841 0.47396164\n",
      "  0.66755774 0.17231987 0.19228902 0.04086862]\n",
      " [0.16893506 0.27859034 0.17701048 0.08870253 0.12063587 0.46077877\n",
      "  0.20633372 0.36426986 0.50341727 0.69039483 0.03931214 0.7994104\n",
      "  0.62790039 0.08175903 0.87357862 0.9208724  0.06107796 0.27687765\n",
      "  0.80620128 0.74825969 0.18452102 0.20934932 0.3704721  0.48452299\n",
      "  0.61825477 0.36891364 0.46253472 0.74747094 0.0366832  0.25243694\n",
      "  0.71334959 0.89520684 0.51167744 0.53211349 0.10717201 0.44741237\n",
      "  0.53261727 0.2424705  0.26924323 0.37728416 0.0200712  0.32207917\n",
      "  0.21144801 0.32749735 0.11976213 0.89052728 0.59359245 0.67910232\n",
      "  0.78917124 0.4984422  0.08692029 0.53710654 0.58684112 0.74543947\n",
      "  0.43165955 0.1275803  0.28377591 0.3630823  0.64591724 0.5707783\n",
      "  0.35609673 0.98651525 0.60577482 0.23722679 0.10178247 0.15285914\n",
      "  0.24595773 0.16068137 0.18656702 0.28509517 0.1733736  0.89676542\n",
      "  0.08023375 0.52451139 0.41039683 0.98237862 0.1120389  0.3978556\n",
      "  0.96947043 0.86550713 0.81707207 0.25790283 0.17088759 0.66864322\n",
      "  0.92937599 0.55676289 0.57161269 0.27997909 0.76949293 0.18704375\n",
      "  0.32367924 0.42543644 0.50761038 0.24240973 0.11483682 0.61062004\n",
      "  0.28863055 0.58123822 0.15436272 0.4811401 ]\n",
      " [0.53258943 0.05182354 0.33660428 0.13441468 0.06337497 0.98996023\n",
      "  0.32235384 0.80987445 0.25464065 0.68150272 0.76022786 0.59563874\n",
      "  0.47157619 0.41184091 0.34886827 0.92952914 0.83061941 0.96502691\n",
      "  0.12429722 0.73086748 0.93834046 0.18123307 0.06649627 0.74112065\n",
      "  0.57447311 0.84182878 0.13977238 0.79526731 0.20162732 0.16365594\n",
      "  0.1642658  0.81457472 0.66519722 0.52306542 0.35883048 0.87720054\n",
      "  0.39244511 0.81659944 0.43913491 0.37694443 0.46267979 0.30137787\n",
      "  0.74760938 0.50272039 0.2322127  0.89957457 0.38389122 0.54355286\n",
      "  0.90647211 0.624238   0.11689804 0.93983212 0.62770805 0.33490561\n",
      "  0.13927207 0.79402519 0.62007276 0.53346109 0.89389258 0.78859721\n",
      "  0.15167488 0.31172207 0.24848914 0.74394629 0.03353243 0.56988968\n",
      "  0.76245869 0.87676564 0.34208175 0.8212573  0.11063174 0.84645229\n",
      "  0.12748866 0.39728729 0.79729537 0.14991743 0.2292514  0.72225257\n",
      "  0.72003654 0.64114763 0.69394844 0.54272444 0.25179906 0.34569599\n",
      "  0.18159772 0.90845056 0.58339179 0.40085142 0.4620058  0.94728334\n",
      "  0.1533514  0.58622983 0.50588868 0.61145424 0.01811018 0.87212391\n",
      "  0.93211828 0.56513318 0.69665082 0.92249938]\n",
      " [0.70723863 0.15253904 0.57628836 0.60671505 0.42413067 0.73644424\n",
      "  0.93436701 0.92556851 0.45083937 0.11323805 0.9848412  0.83889809\n",
      "  0.12466268 0.92084188 0.86989636 0.51883806 0.59127544 0.3990027\n",
      "  0.05476164 0.33519724 0.80285345 0.00463202 0.33349917 0.39816869\n",
      "  0.5373956  0.91985562 0.34634599 0.3469532  0.73750125 0.45221794\n",
      "  0.22460482 0.45243952 0.14085702 0.17638699 0.49836777 0.41892545\n",
      "  0.9148459  0.3623939  0.58058835 0.63226429 0.01309446 0.66353737\n",
      "  0.17803597 0.96107032 0.14866273 0.41462412 0.08534967 0.99687425\n",
      "  0.50219501 0.59538502 0.06707648 0.74996047 0.20990559 0.89805429\n",
      "  0.20513964 0.19068772 0.03654967 0.47206695 0.56484113 0.06570864\n",
      "  0.77552762 0.45328883 0.52439027 0.44076275 0.40076306 0.55964033\n",
      "  0.15524025 0.18192813 0.86178562 0.94611546 0.37330932 0.27074467\n",
      "  0.64399954 0.40873417 0.02538636 0.1561526  0.71597223 0.65892394\n",
      "  0.02709599 0.22197216 0.2310748  0.67189274 0.01971054 0.10410858\n",
      "  0.79991609 0.17854466 0.65274611 0.23818278 0.09944139 0.24317219\n",
      "  0.72226693 0.85569647 0.83021986 0.39718353 0.66808514 0.2049843\n",
      "  0.29314773 0.89633582 0.01300192 0.08550853]\n",
      " [0.20788626 0.0265322  0.18143544 0.58304156 0.42142455 0.89267171\n",
      "  0.81744356 0.34181735 0.25942343 0.37969241 0.59029494 0.26806364\n",
      "  0.62414891 0.40941165 0.55204718 0.43612653 0.29446576 0.94845331\n",
      "  0.76360579 0.14011318 0.86846798 0.4874312  0.89455223 0.79985526\n",
      "  0.4252135  0.02246931 0.26867736 0.54163421 0.63347822 0.25788769\n",
      "  0.13935607 0.83493024 0.98440218 0.52569018 0.17167929 0.27230733\n",
      "  0.01839068 0.91429881 0.11775108 0.57651648 0.27405522 0.554178\n",
      "  0.65142039 0.8297418  0.20642127 0.01099583 0.13688563 0.90001864\n",
      "  0.87389008 0.5974131  0.60051686 0.66503667 0.17537128 0.91441195\n",
      "  0.41877052 0.38313853 0.51891771 0.04696597 0.16628337 0.73803362\n",
      "  0.08279867 0.60315211 0.24534911 0.38929561 0.28869374 0.35567272\n",
      "  0.71904591 0.29712172 0.56640464 0.4760504  0.66367117 0.93682974\n",
      "  0.7325721  0.21494038 0.03118314 0.26226404 0.59507793 0.05142581\n",
      "  0.49636625 0.59684285 0.33424389 0.7709122  0.10659825 0.07513778\n",
      "  0.72818876 0.49549132 0.6884024  0.43482734 0.24640203 0.81910232\n",
      "  0.79941588 0.69469647 0.27214514 0.59023067 0.3609739  0.09158207\n",
      "  0.91731358 0.13681863 0.95023735 0.44600577]]\n",
      "Epoch 1/30\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 5.5919\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 5.2596\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2579\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2577\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2576\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2576\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 5.2575\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 5.2575\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 5.2575\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2575\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.7058329582214355"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Fetch user and post data\n",
    "users_url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "posts_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "\n",
    "users_response = requests.get(users_url)\n",
    "posts_response = requests.get(posts_url)\n",
    "\n",
    "# Initialize the Hugging Face zero-shot classification pipeline\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name, device=0)\n",
    "\n",
    "# Define candidate labels\n",
    "candidate_labels = [\"Sports\", \"Medical\", \"Tech\"]\n",
    "\n",
    "# Initialize dataset size\n",
    "num_users = 10\n",
    "num_articles = 100\n",
    "\n",
    "if users_response.status_code == 200 and posts_response.status_code == 200:\n",
    "    users = users_response.json()\n",
    "    posts = posts_response.json()\n",
    "    \n",
    "    # Prepare user data\n",
    "    user_data = []\n",
    "    title_data = []\n",
    "    \n",
    "    for user in users[:num_users]:  # Limit users to `num_users`\n",
    "        user_id = user['id']\n",
    "        user_name = user['name']\n",
    "        \n",
    "        # Filter posts by user_id\n",
    "        user_posts = [post['title'] for post in posts if post['userId'] == user_id]\n",
    "        \n",
    "        # Append user data\n",
    "        user_data.append({\n",
    "            'id': user_id,\n",
    "            'name': user_name,\n",
    "            'news titles': user_posts,\n",
    "            'Sports': random.randint(1, 5),\n",
    "            'Medical': random.randint(1, 5),\n",
    "            'Tech': random.randint(1, 5),\n",
    "            'Watch Time': round(random.uniform(0, 24), 2)\n",
    "        })\n",
    "        \n",
    "        for title in user_posts[:num_articles]:  # Limit articles to `num_articles`\n",
    "            result = classifier(title, candidate_labels)\n",
    "            category = result['labels'][0]\n",
    "            title_data.append({\n",
    "                'News Title': title,\n",
    "                'Sports': 1 if category == \"Sports\" else 0,\n",
    "                'Medical': 1 if category == \"Medical\" else 0,\n",
    "                'Tech': 1 if category == \"Tech\" else 0,\n",
    "            })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    user_df = pd.DataFrame(user_data)\n",
    "    title_df = pd.DataFrame(title_data)\n",
    "    \n",
    "    # Extract features\n",
    "    user_features = user_df.drop(columns=['id', 'name', 'news titles', 'Watch Time'])\n",
    "    article_features = title_df.drop(columns=['News Title'])\n",
    "    \n",
    "    # Generate random interaction data\n",
    "    interactions = np.random.rand(num_users, num_articles)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    print(user_df)\n",
    "    print(title_df)\n",
    "    print(user_features)\n",
    "    print(article_features)\n",
    "    print(interactions)\n",
    "    # Scale features and interactions\n",
    "    scaler_user = StandardScaler()\n",
    "    scaler_article = StandardScaler()\n",
    "    scaler_target = MinMaxScaler((0, 5))\n",
    "    \n",
    "    user_features_scaled = scaler_user.fit_transform(user_features)\n",
    "    article_features_scaled = scaler_article.fit_transform(article_features)\n",
    "    interaction_scaled = scaler_target.fit_transform(interactions)\n",
    "\n",
    "    # Find all valid (user, article) pairs from the interaction matrix\n",
    "    user_indices, article_indices = np.where(~np.isnan(interaction_scaled))\n",
    "    y = interaction_scaled[user_indices, article_indices]  # Corresponding interaction scores\n",
    "\n",
    "\n",
    "        # Gather the features for the valid user-article pairs\n",
    "    user_features_for_training = user_features_scaled[user_indices]  # Shape: (num_samples, num_user_features)\n",
    "    article_features_for_training = article_features_scaled[article_indices]  # Shape: (num_samples, num_article_features)\n",
    "\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    user_train, user_test, article_train, article_test, y_train, y_test = train_test_split(\n",
    "        user_features_for_training,\n",
    "        article_features_for_training,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "        # Reshape interaction scores for compatibility with the model\n",
    "    #interaction_train = interaction_train.flatten().reshape(-1, 1)\n",
    "    #interaction_test = interaction_test.flatten().reshape(-1, 1)\n",
    "            \n",
    "            # Reshape targets to match batch sizes\n",
    "    #y_train = y_train.reshape(-1, 1)\n",
    "    #y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Error fetching data from APIs\")\n",
    "\n",
    "# Build the neural network model\n",
    "num_user_features = user_features_scaled.shape[1]\n",
    "num_item_features = article_features_scaled.shape[1]\n",
    "num_outputs = 32\n",
    "\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "# User input\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# Item input\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# Dot product output\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# Compile model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "# Train the model\n",
    "model.fit([user_train, article_train], y_train, epochs=30, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate([user_test, article_test], y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.76930347, -1.06904497,  1.57142857],\n",
       "       [ 1.17953565,  1.60356745,  0.14285714],\n",
       "       [ 1.17953565, -1.06904497,  0.85714286],\n",
       "       ...,\n",
       "       [ 0.44232587,  0.26726124,  0.14285714],\n",
       "       [ 1.17953565,  1.60356745,  1.57142857],\n",
       "       [-0.29488391,  0.93541435, -0.57142857]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_train.shape)\n",
    "user_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.14285714, -0.56195149,  0.59274898],\n",
       "       [-0.14285714, -0.56195149,  0.59274898],\n",
       "       [-0.14285714, -0.56195149,  0.59274898],\n",
       "       ...,\n",
       "       [-0.14285714, -0.56195149,  0.59274898],\n",
       "       [-0.14285714, -0.56195149,  0.59274898],\n",
       "       [ 7.        , -0.56195149, -1.68705478]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(article_train.shape)\n",
    "article_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 5.        , 3.09254812, 0.        , 5.        ,\n",
       "       2.94432332, 5.        , 3.80071389, 1.55968705, 2.67376215,\n",
       "       2.85618535, 0.        , 0.        , 0.59862018, 0.        ,\n",
       "       3.5415253 , 0.36747302, 5.        , 1.80916439, 1.32088994,\n",
       "       4.92807564, 1.70083647, 0.6663126 , 0.65856132, 0.03509917,\n",
       "       5.        , 3.77924972, 2.41582185, 2.12066562, 4.63635378,\n",
       "       2.40202862, 1.95101974, 3.35969698, 4.74233848, 5.        ,\n",
       "       0.        , 2.00262634, 2.56889301, 5.        , 0.08817303,\n",
       "       3.14845285, 3.21641527, 0.        , 4.66302484, 2.61454647,\n",
       "       0.        , 0.02698861, 0.28103528, 0.8651268 , 2.7219798 ,\n",
       "       1.71930003, 3.82238094, 5.        , 3.69859485, 3.83750055,\n",
       "       1.16028979, 0.07265242, 1.51640825, 4.58290537, 0.74838387,\n",
       "       3.88359628, 1.62659244, 2.13459109, 3.38970094, 3.80025129,\n",
       "       4.75461037, 3.55551259, 0.        , 4.36980434, 3.36540044,\n",
       "       2.2143455 , 4.49214124, 1.30552384, 1.25966959, 5.        ,\n",
       "       4.86399065, 3.39808442, 0.        , 2.94166106, 1.73321604,\n",
       "       0.        , 2.97420702, 0.5377264 , 0.        , 3.44066649,\n",
       "       5.        , 3.52589291, 0.        , 0.97420817, 2.95532169,\n",
       "       0.28610383, 5.        , 2.75683851, 5.        , 2.32450322,\n",
       "       1.05874554, 1.28080235, 1.9430858 , 4.67535605, 0.72060835,\n",
       "       2.41130045, 0.37785349, 2.40242352, 0.13675747, 3.67656695,\n",
       "       3.33922384, 0.        , 0.47515845, 0.6833005 , 1.85849988,\n",
       "       5.        , 5.        , 5.        , 4.36760597, 1.78032099,\n",
       "       4.94638854, 5.        , 3.23304888, 1.09974249, 3.38614525,\n",
       "       0.        , 0.        , 3.32248872, 0.16795424, 3.86897206,\n",
       "       4.86625428, 0.78828594, 4.95820927, 2.90078157, 1.39480335,\n",
       "       0.28222541, 0.        , 0.        , 1.25866791, 2.53851832,\n",
       "       2.26027451, 1.5079039 , 3.29071443, 3.70539886, 5.        ,\n",
       "       2.93686003, 1.52023936, 2.93988058, 2.25453897, 1.83624305,\n",
       "       4.02654796, 2.56109918, 3.05203443, 0.46402886, 2.78048728,\n",
       "       0.        , 2.90304177, 0.67567663, 5.        , 0.        ,\n",
       "       0.31104732, 0.1498391 , 0.        , 2.48777412, 1.68925979,\n",
       "       2.6252268 , 2.20881725, 1.56229309, 3.93387272, 0.30559382,\n",
       "       3.30734452, 1.30564848, 3.78196923, 3.8260649 , 0.40907619,\n",
       "       2.84205488, 5.        , 5.        , 0.08273947, 0.        ,\n",
       "       4.74539992, 4.99910918, 4.29987756, 2.95414305, 4.76270271,\n",
       "       4.48368016, 0.13826992, 2.25463794, 0.8114157 , 3.13796547,\n",
       "       4.71134017, 4.93284409, 0.53689281, 4.00474849, 4.6112897 ,\n",
       "       3.57613665, 1.65606724, 0.        , 1.18411932, 0.16806963,\n",
       "       0.41705646, 4.51855348, 1.93010556, 3.44331999, 0.36054279,\n",
       "       2.22059695, 4.753236  , 0.26846836, 5.        , 4.02910437,\n",
       "       0.55040991, 0.77351822, 3.02827621, 3.82403041, 4.43682194,\n",
       "       2.04917752, 4.53654365, 2.47675516, 4.54342121, 1.42540794,\n",
       "       3.8353032 , 0.83524793, 0.64374848, 5.        , 3.72055653,\n",
       "       2.02239956, 5.        , 3.46473929, 5.        , 0.        ,\n",
       "       5.        , 0.        , 0.37566365, 1.28712343, 5.        ,\n",
       "       0.        , 2.20411792, 0.        , 0.        , 3.58069391,\n",
       "       4.36144994, 5.        , 0.8977238 , 3.22204944, 4.95207536,\n",
       "       1.7598381 , 2.26928544, 4.08624706, 3.87573169, 1.85402334,\n",
       "       2.61279778, 2.54193023, 4.00180381, 0.        , 2.21660414,\n",
       "       1.17020863, 1.38761094, 5.        , 3.57299737, 5.        ,\n",
       "       0.3325762 , 0.8171979 , 1.17562856, 1.00266135, 5.        ,\n",
       "       4.07102406, 4.12288627, 0.93243407, 2.51057216, 5.        ,\n",
       "       5.        , 3.5502989 , 0.98120393, 2.4862417 , 3.00119946,\n",
       "       0.11026587, 4.02835331, 0.        , 2.01357824, 4.668777  ,\n",
       "       0.86348887, 2.70791492, 2.50404639, 2.3021955 , 1.33901342,\n",
       "       4.04369965, 4.28403125, 5.        , 4.42729653, 2.6794582 ,\n",
       "       4.60806921, 0.        , 1.22991246, 0.17348062, 0.        ,\n",
       "       4.16413802, 0.57717872, 3.29108114, 0.        , 1.81075551,\n",
       "       4.8262875 , 5.        , 1.50825412, 2.26512679, 0.        ,\n",
       "       4.52753665, 2.01182939, 5.        , 1.06347255, 3.59798551,\n",
       "       0.        , 5.        , 5.        , 2.7441795 , 5.        ,\n",
       "       4.55249377, 2.82751113, 0.        , 0.86937618, 5.        ,\n",
       "       4.74113125, 0.15042038, 0.14441559, 0.07113427, 1.24885905,\n",
       "       0.08195095, 0.64024024, 1.54631233, 2.52025063, 3.5636222 ,\n",
       "       4.37416572, 0.44389955, 5.        , 4.260989  , 3.17152166,\n",
       "       3.96596438, 0.19559964, 1.68236515, 2.65240673, 0.83531253,\n",
       "       0.2071713 , 2.17250899, 3.43450298, 0.18491509, 5.        ,\n",
       "       2.52775738, 4.1620322 , 1.46344   , 1.49489011, 0.08383979,\n",
       "       4.00537637, 4.90338536, 5.        , 3.50941574, 4.06991906,\n",
       "       4.82491306, 4.84177693, 0.46140854, 1.14077346, 2.92169681,\n",
       "       3.23584988, 0.        , 1.84573825, 1.25665385, 3.52406134,\n",
       "       1.53500416, 2.14280706, 2.45949692, 2.08629734, 3.45341283,\n",
       "       0.52836021, 4.9372148 , 3.92515419, 1.50838455, 3.52398759,\n",
       "       1.26798916, 0.94937682, 3.48511446, 5.        , 0.        ,\n",
       "       2.18320368, 2.62846491, 0.        , 3.77468768, 1.93029651,\n",
       "       2.41905175, 1.06553225, 0.27945062, 0.6398465 , 2.35926591,\n",
       "       0.        , 1.25301368, 0.        , 4.81300313, 0.14500372,\n",
       "       4.89890542, 4.12695582, 0.        , 0.37539449, 2.90286106,\n",
       "       5.        , 4.06706322, 0.13484141, 1.51981675, 1.52866195,\n",
       "       2.21957588, 4.78045152, 3.28586005, 2.70190255, 2.28085951,\n",
       "       1.37384385, 0.32605312, 4.67852643, 0.        , 0.84590274,\n",
       "       1.44396102, 2.73118483, 5.        , 2.41136102, 4.31018422,\n",
       "       2.98461703, 3.20804006, 4.02445863, 3.65476679, 3.47943681,\n",
       "       2.33308171, 5.        , 3.64429727, 0.        , 1.57992973,\n",
       "       1.9058014 , 2.71466476, 4.82665793, 1.37441399, 0.        ,\n",
       "       0.19177102, 3.31178398, 0.18689691, 0.37283916, 3.51843776,\n",
       "       1.23425292, 0.35944948, 1.90257206, 4.48067118, 3.03793281,\n",
       "       4.88850503, 3.572701  , 0.41212113, 1.48593708, 0.27361728,\n",
       "       4.87104231, 0.91611369, 0.        , 0.        , 2.80159894,\n",
       "       1.82614977, 0.73529441, 1.97724942, 4.47669942, 2.21622746,\n",
       "       0.63283639, 0.94962713, 3.04400922, 3.5902847 , 1.34620266,\n",
       "       0.        , 0.68172084, 3.41760251, 4.19520318, 0.46421327,\n",
       "       5.        , 3.93698643, 2.5922535 , 4.40281536, 4.31710983,\n",
       "       0.27601725, 0.19705818, 3.72993906, 0.43358836, 2.81500003,\n",
       "       4.86969274, 0.        , 4.55487698, 0.        , 3.56751994,\n",
       "       3.35579872, 5.        , 0.80967045, 3.15459535, 5.        ,\n",
       "       1.596416  , 1.7576498 , 2.12449878, 1.02456543, 3.38782643,\n",
       "       1.65736463, 4.02324781, 2.55762834, 3.31284367, 4.7585716 ,\n",
       "       0.02681053, 0.09710923, 0.8426318 , 3.5408432 , 4.66028705,\n",
       "       2.13030055, 0.03674472, 0.57374729, 2.51015475, 3.93443091,\n",
       "       5.        , 2.40326459, 2.91019738, 5.        , 4.00633913,\n",
       "       1.65984161, 3.49341299, 1.77129294, 3.89925165, 3.98617408,\n",
       "       5.        , 0.        , 4.89116337, 2.63753291, 0.        ,\n",
       "       0.67628872, 5.        , 4.72774377, 4.53501256, 1.46245011,\n",
       "       0.53043564, 1.39197565, 4.99918505, 0.        , 5.        ,\n",
       "       1.90325847, 2.33667087, 4.93772085, 3.05542242, 4.33284453,\n",
       "       2.09171017, 1.07438412, 2.8370573 , 1.22561092, 3.01231248,\n",
       "       0.        , 0.61763947, 4.626314  , 1.859783  , 5.        ,\n",
       "       0.47830287, 2.26847165, 3.03807393, 5.        , 0.        ,\n",
       "       3.12432819, 0.        , 0.49713681, 1.53275204, 4.21942899,\n",
       "       5.        , 3.63787478, 1.37555528, 5.        , 2.2923946 ,\n",
       "       4.88700703, 2.25667454, 2.86339631, 4.77781834, 1.9318918 ,\n",
       "       4.61652107, 3.35146984, 3.79338649, 0.81573755, 2.30839917,\n",
       "       5.        , 0.24797945, 0.        , 4.04374052, 1.54901253,\n",
       "       0.        , 4.65921006, 5.        , 2.93202318, 1.35923995,\n",
       "       3.85858779, 2.53136839, 1.9661827 , 5.        , 3.70078503,\n",
       "       1.15703833, 5.        , 4.97777378, 0.21843065, 0.        ,\n",
       "       0.78214543, 1.6617493 , 3.00728327, 3.53931779, 4.50401624,\n",
       "       4.28809573, 0.39725482, 3.19819383, 4.69708342, 0.        ,\n",
       "       0.66317817, 0.12406096, 5.        , 4.65064856, 1.65752608,\n",
       "       5.        , 0.73518742, 4.58236397, 4.35063118, 4.24578091,\n",
       "       4.95577899, 4.17338379, 1.97299758, 3.60293311, 3.02443999,\n",
       "       5.        , 1.19750639, 2.48856589, 2.39648108, 0.        ,\n",
       "       4.88419105, 4.05020106, 5.        , 1.52696611, 0.25065777,\n",
       "       2.64814006, 0.        , 0.24756791, 1.32308944, 0.        ,\n",
       "       2.14345766, 3.78861372, 2.47064953, 3.61989068, 0.5487124 ,\n",
       "       1.74491746, 1.00547608, 1.29197432, 3.25612254, 2.73057487,\n",
       "       0.15659735, 4.56525501, 3.71713179, 0.06457923, 2.13669351,\n",
       "       4.24762082, 2.91526722, 1.88933207, 1.29652804, 2.49463461,\n",
       "       0.25786942, 3.50354789, 3.09352484, 4.5175638 , 4.87645931,\n",
       "       1.96018638, 0.73143329, 4.8657127 , 4.64155806, 0.70783191,\n",
       "       4.17759892, 1.09933276, 3.31231752, 2.30000531, 2.18213538,\n",
       "       0.        , 5.        , 2.08905879, 5.        , 5.        ,\n",
       "       3.33027601, 0.        , 3.38020837, 2.71689529, 3.93240639,\n",
       "       0.78699437, 1.33206649, 0.53667252, 0.8245588 , 3.57256215,\n",
       "       0.57377918, 0.66455151, 1.1071057 , 4.19048297, 5.        ,\n",
       "       1.71739767, 3.19166383, 5.        , 0.        , 3.81660108,\n",
       "       4.68673784, 4.16546166, 2.88036664, 2.56597883, 0.1368309 ,\n",
       "       1.03914054, 0.        , 2.80692272, 2.29792012, 4.88496512,\n",
       "       2.72637129, 2.80212182, 1.22193067, 0.31166889, 2.69815489,\n",
       "       1.73677874, 0.71617711, 4.73943772, 1.53389053, 0.        ,\n",
       "       0.        , 4.35262928, 1.22402218, 3.20215988, 4.1170982 ,\n",
       "       5.        , 5.        , 0.4800516 , 0.        , 4.82572879,\n",
       "       0.        , 5.        , 0.        , 5.        , 5.        ,\n",
       "       0.22199512, 5.        , 3.9302366 , 0.09256943, 4.9952742 ,\n",
       "       1.70709363, 3.23018688, 1.00803473, 4.77743296, 0.74118318,\n",
       "       3.7070155 , 1.01734208, 0.47731419, 5.        , 1.09632586,\n",
       "       0.        , 0.62811609, 2.82152888, 0.        , 2.69275406,\n",
       "       1.39976497, 3.68018512, 1.6999372 , 0.5246988 , 1.53194035,\n",
       "       0.03697995, 0.        , 3.40880276, 0.56545   , 1.282281  ,\n",
       "       2.3286357 , 5.        , 0.83334947, 3.07402945, 0.        ,\n",
       "       3.0007667 , 4.48430155, 0.13622401, 2.61803506, 4.44398554,\n",
       "       0.75641053, 5.        , 0.36734069, 2.05696951, 4.69795477,\n",
       "       1.60871319, 5.        , 4.39846055, 3.70755753, 2.7908093 ,\n",
       "       3.38880329, 1.0070808 , 4.09741142, 4.18171141, 4.97723171,\n",
       "       2.06411566, 1.52647127, 1.33304964, 0.35448971, 0.51605144,\n",
       "       5.        , 0.06187682, 1.6080338 , 4.02578944, 0.88256615,\n",
       "       5.        , 5.        , 2.83444452, 3.70785173, 0.95525843,\n",
       "       2.01019048, 5.        , 5.        , 3.65162257, 1.338855  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Recommended articles for User 3:\n",
      "1. at nam consequatur ea labore ea harum\n",
      "2. laboriosam dolor voluptates\n",
      "3. temporibus sit alias delectus eligendi possimus magni\n",
      "4. quas fugiat ut perspiciatis vero provident\n",
      "5. quaerat velit veniam amet cupiditate aut numquam ut sequi\n"
     ]
    }
   ],
   "source": [
    "# Function to recommend top 5 articles for a given user index\n",
    "def recommend_articles(user_index, user_features_scaled, article_features_scaled, title_df, model, top_n=5):\n",
    "    # Extract the specific user's features\n",
    "    user_feature = user_features_scaled[user_index].reshape(1, -1)  # Reshape to maintain batch compatibility\n",
    "    \n",
    "    # Predict interaction scores for the user with all articles\n",
    "    predictions = model.predict([np.repeat(user_feature, article_features_scaled.shape[0], axis=0), article_features_scaled])\n",
    "    \n",
    "    # Sort articles by predicted scores in descending order\n",
    "    top_articles_indices = predictions.flatten().argsort()[::-1][:top_n]\n",
    "    \n",
    "    # Retrieve the titles of the recommended articles\n",
    "    recommended_articles = title_df.iloc[top_articles_indices]['News Title'].values\n",
    "    \n",
    "    return recommended_articles\n",
    "\n",
    "# Example usage\n",
    "user_index = 3  # Specify the index of the user to recommend articles for\n",
    "recommended_articles = recommend_articles(user_index, user_features_scaled, article_features_scaled, title_df, model)\n",
    "\n",
    "print(f\"Recommended articles for User {user_index}:\")\n",
    "for i, article in enumerate(recommended_articles, start=1):\n",
    "    print(f\"{i}. {article}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
